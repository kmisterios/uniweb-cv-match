import json
from copy import deepcopy
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

from utils.hardcode_data import candidate_names, map_names
from utils.utils import *

if "computed" not in st.session_state:
    st.session_state["computed"] = False


st.title("–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ üíº")

vacancy_df = load_data(path="./data/vacancies.csv")
selector, config = load_model(config_path="./config/config.yaml")

vacancies = vacancy_df["–î–æ–ª–∂–Ω–æ—Å—Ç—å"].to_list()

features = deepcopy(config["model"]["stage_2"]["ranking_features"])
info_dict = {"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞": [], "–í–µ—Å": []}
for feature, value in zip(features, config["model"]["stage_2"]["weights"]):
    info_dict["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"].append(
        feature if feature not in map_names else map_names[feature]
    )
    info_dict["–í–µ—Å"].append(round(value, 2))

df_info = pd.DataFrame(info_dict)
with st.sidebar:
    st.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ‚ÑπÔ∏è")
    st.write("–í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞.")
    st.markdown(df_info.to_html(escape=False), unsafe_allow_html=True)

option = st.selectbox(
    "–í–∞–∫–∞–Ω—Å–∏–∏",
    vacancies,
    index=None,
    placeholder="–í—ã–±–µ—Ä–µ—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é...",
)

if option is not None:
    vacancy = vacancy_df[vacancy_df["–î–æ–ª–∂–Ω–æ—Å—Ç—å"] == option].iloc[0].to_dict()
    st.header(f"{option}", divider="blue")
    col1, col2 = st.columns(2)
    with col1:
        col1_container = st.container(border=True, height=100)
        col1_container.caption("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å")
        col1_container.markdown(f"**{vacancy['prof_field_full']}**")
    with col2:
        col2_container = st.container(border=True, height=100)
        text = vacancy["–°–ø–∏—Å–æ–∫ –Ω–∞–≤—ã–∫–æ–≤"]
        col2_container.caption("–°–ø–∏—Å–æ–∫ –Ω–∞–≤—ã–∫–æ–≤")
        col2_container.markdown(f"**{text}**")
    container = st.container(border=True)
    container.caption("–û–ø–∏—Å–∞–Ω–∏–µ")
    container.write(vacancy["–û–ø–∏—Å–∞–Ω–∏–µ"])
    if st.button("–ü–æ–¥–æ–±—Ä–∞—Ç—å", type="primary"):
        df_cv = load_data(f"./data/{option}.csv")
        with st.status("–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..."):
            if (
                not Path("./tmp_cvs.csv").exists()
                or config["general"]["mode"] == "prod"
            ):
                st.write(f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_cv.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")
                df_ranked_1st = selector.rank_first_stage(
                    vacancy=vacancy, df_relevant=df_cv.copy()
                )
                st.write(f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_ranked_1st.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")
                df_ranked_2nd, vacancy_prep, nan_mask = selector.rank_second_stage(
                    vacancy=vacancy, df_relevant=df_ranked_1st.copy()
                )
                if config["general"]["mode"] != "prod":
                    df_ranked_2nd.to_csv("./tmp_cvs.csv", index=False)
                    with open("./tmp_vac.json", "w") as f:
                        json.dump(vacancy_prep, f, ensure_ascii=False)
                    np.save("./tmp_mask.npy", nan_mask)
            else:
                df_ranked_2nd = pd.read_csv("./tmp_cvs.csv")
                with open("./tmp_vac.json", "r") as f:
                    vacancy_prep = json.load(f)
                nan_mask = np.load("./tmp_mask.npy")

            data_cv = df2dict(df_ranked_2nd)
            st.session_state["computed"] = True
            st.write(f"–í—ã–±—Ä–∞–Ω–æ {df_ranked_2nd.shape[0]} –ª—É—á—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.")
        if st.session_state["computed"]:
            nan_mask = np.delete(nan_mask, [1, 2, 5])
            st.subheader("–ö–∞–Ω–¥–∏–¥–∞—Ç—ã", divider="blue")
            for key in data_cv:
                col1_results, col2_cv = st.columns(2)
                key_ = data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
                if "(" in key and ")" not in key:
                    key_ += ")"
                key_ += f" ({round(data_cv[key]['sim_score_second'] * 100)}% match)"
                key_ = np.random.choice(candidate_names) + f" - {key_}"
                with st.expander(key_):
                    match_score_first = round(data_cv[key]["sim_score_first"] * 100)
                    accent_color = select_color(match_score_first)
                    st.markdown(
                        f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_first}% match]"
                    )

                    match_score_second = round(data_cv[key]["sim_score_second"] * 100)
                    accent_color = select_color(match_score_second)
                    st.markdown(
                        f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_second}% match]"
                    )

                    match_score_full_desc = round(
                        data_cv[key]["Full_description_sim"] * 100
                    )
                    accent_color = select_color(match_score_second)
                    st.markdown(
                        f"–ü–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –ø–æ–ª–Ω–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é: :{accent_color}[{match_score_full_desc}% match]"
                    )

                    ranking_features = deepcopy(
                        config["model"]["stage_2"]["ranking_features"]
                    )
                    ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                    ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                    ranking_features.remove("Full_description")
                    job_labels = [
                        "–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim",
                        "–î–æ–ª–∂–Ω–æ—Å—Ç—å_cat_sim",
                        "–î–æ–ª–∂–Ω–æ—Å—Ç—å_subcat_sim",
                    ]
                    data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim"] = (
                        sum([data_cv[key][job_label] for job_label in job_labels]) / 3
                    )
                    for i, feature in enumerate(ranking_features):
                        col_results_1, col_results_2, col_results_3 = st.columns(
                            [2, 1, 2], gap="small", vertical_alignment="center"
                        )
                        num_rows = (
                            max(len(data_cv[key][feature]), len(vacancy_prep[feature]))
                            / 20
                        )
                        container_height = round(num_rows * 30) + 60
                        with col_results_1:
                            if i == 0:
                                st.header("–ö–∞–Ω–¥–∏–¥–∞—Ç")
                            container_cv = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_cv.caption(feature_print)
                            formated_text = format_intersection(
                                vacancy_prep[feature],
                                data_cv[key][feature],
                            )
                            container_cv.markdown(formated_text.capitalize())

                        with col_results_2:
                            if i == 0:
                                st.header(" ")
                            container_score = st.container(
                                border=True, height=container_height
                            )
                            match_score = round(data_cv[key][f"{feature}_sim"] * 100)
                            flag_vac = False
                            flag_cv = False
                            if nan_mask[i] == 0:
                                match_score = 0
                                flag_vac = True
                            if data_cv[key][feature].lower() in [
                                "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                                "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                                "",
                                "none",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                            ]:
                                match_score = 0
                                flag_cv = True
                            if flag_vac * flag_cv:
                                match_score = 0
                            accent_color = select_color(match_score)
                            container_score.markdown(
                                "<br>" * int((num_rows // 2)), unsafe_allow_html=True
                            )
                            container_score.markdown(
                                f":{accent_color}[{match_score}%\nmatch]"
                            )

                        with col_results_3:
                            if i == 0:
                                st.header("–í–∞–∫–∞–Ω—Å–∏—è")
                            container_vac = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_vac.caption(feature_print)
                            formated_text = format_intersection(
                                data_cv[key][feature], vacancy_prep[feature]
                            )
                            container_vac.markdown(formated_text.capitalize())
                        if feature == "–î–æ–ª–∂–Ω–æ—Å—Ç—å":
                            st.info(
                                "–£–∫–∞–∑–∞–Ω–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 3 —Å–∫–æ—Ä–æ–≤ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –î–æ–ª–∂–Ω–æ—Å—Ç—å—é.",
                                icon="‚ÑπÔ∏è",
                            )
                        if i < len(ranking_features) - 1:
                            st.divider()
